{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "celltoolbar": "Edit Metadata",
    "coursera": {
      "course_slug": "guided-tour-machine-learning-finance"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "linear_regress_m1_ex2_v4-newV.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blackfry/notebooks/blob/main/linear_regress_m1_ex2_v4_newV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te2-dQDkY3Cf"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "Welcome to your second assignment. This exercise gives you a brief introduction to linear regression. The exercise is to be implemented in Python. Even if you've used Python before, this will help familiarize you with functions we'll need.  \n",
        "\n",
        "**Instructions:**\n",
        "- You will be using Python 3.\n",
        "- Avoid using for-loops and while-loops, unless you are explicitly told to do so.\n",
        "- Do not modify the (# GRADED FUNCTION [function name]) comment in some cells. Your work would not be graded if you change this. Each cell containing that comment should only contain one function.\n",
        "- After coding your function, run the cell right below it to check if your result is correct.\n",
        "- The token generated by Coursera (COURSERA_TOKEN) expires every <b>30 minutes</b>. It is advisable to always work with the most recent generated token so as to avoid any submission related errors. If you receive such error messages, rerun the cells containing your code and the GRADED FUNCTION in the same order. \n",
        "\n",
        "\n",
        "**After this assignment you will:**\n",
        "- Be able to implement linear regression model using statsmodels, scikit-learn, and tensorflow\n",
        "- Work with simulated non-linear dataset\n",
        "- Compare model performance (quality of fit) of both models\n",
        "\n",
        "- - The blue button \"Submit Assignment\" does not work. After running all the cells, please go directly to Assignment-> My submission to see your results.\n",
        "\n",
        "Let's get started!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiW_spUbY3Cj"
      },
      "source": [
        "## About iPython Notebooks ##\n",
        "\n",
        "iPython Notebooks are interactive coding environments embedded in a webpage. You will be using iPython notebooks in this class. You only need to write code between the ### START CODE HERE ### and ### END CODE HERE ### comments. After writing your code, you can run the cell by either pressing \"SHIFT\"+\"ENTER\" or by clicking on \"Run Cell\" (denoted by a play symbol) in the upper bar of the notebook. \n",
        "\n",
        "We will often specify \"(â‰ˆ X lines of code)\" in the comments to tell you about how much code you need to write. It is just a rough estimate, so don't feel bad if your code is longer or shorter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "RvskmRF6Y3Cn"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import grading\n",
        "\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    %matplotlib inline\n",
        "except: pass\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.layers import core as core_layers\n",
        "try:\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "except: pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "hqGcGlG9Y3Co"
      },
      "source": [
        "### ONLY FOR GRADING. DO NOT EDIT ###\n",
        "submissions=dict()\n",
        "assignment_key=\"QNZTAPW2Eeeg_w5MCivhhg\" \n",
        "all_parts=[\"dtA5d\", \"2inmf\", \"FCpek\",\"78aDd\",\"qlQVj\"]\n",
        "### ONLY FOR GRADING. DO NOT EDIT ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "LHnb06pHY3Cp"
      },
      "source": [
        "COURSERA_TOKEN = \""# the key provided to the Student under his/her email on submission page\n",
        "COURSERA_EMAIL = \""# the email"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "XjkQyBLSY3Cq"
      },
      "source": [
        "def reset_graph(seed=42):\n",
        "    \"\"\"\n",
        "    Utility function to reset current tensorflow computation graph\n",
        "    and set the random seed \n",
        "    \"\"\"\n",
        "    # to make results reproducible across runs\n",
        "    tf.reset_default_graph()\n",
        "    tf.set_random_seed(seed)\n",
        "    np.random.seed(seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "UuykpFowY3Cq"
      },
      "source": [
        "## We use artificial data for the following two specifications of regression:\n",
        "\n",
        "### Linear Regression\n",
        "\n",
        "$ y(x) = a + b_1 \\cdot X_1 + b_2 \\cdot X_2 + b_3 \\cdot X_3 + \\sigma \\cdot \\varepsilon $ \n",
        "\n",
        "where $ \\varepsilon \\sim N(0, 1) $ is a Gaussian noise, and $ \\sigma $ is its volatility, \n",
        "with the following choice of parameters:\n",
        "\n",
        "$ a = 1.0 $\n",
        "\n",
        "$ b_1, b_2, b_3 = (0.5, 0.2, 0.1) $\n",
        "\n",
        "$ \\sigma = 0.1 $\n",
        "\n",
        "$ X_1, X_2, X_3 $ will be uniformally distributed in $ [-1,1] $\n",
        "\n",
        "### Non-Linear Regression\n",
        "\n",
        "$ y(x) = a + w_{00} \\cdot X_1 + w_{01} \\cdot X_2 + w_{02} \\cdot X_3 + + w_{10} \\cdot X_1^2 \n",
        "+ w_{11} \\cdot X_2^2 + w_{12} \\cdot X_3^2 +  \\sigma \\cdot \\varepsilon $ \n",
        "\n",
        "where\n",
        "\n",
        "$ w = [[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]]  $\n",
        "\n",
        "and the rest of parameters is as above, with the same values of $ X_i $"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "TKaxGIr4Y3Cr"
      },
      "source": [
        "### Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkCXXpvsY3Cs",
        "outputId": "4a22dc9b-220e-4a6a-a889-f99f12f59ab8"
      },
      "source": [
        "def generate_data(n_points=10000, n_features=3, use_nonlinear=True, \n",
        "                    noise_std=0.1, train_test_split = 4):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    n_points - number of data points to generate\n",
        "    n_features - a positive integer - number of features\n",
        "    use_nonlinear - if True, generate non-linear data\n",
        "    train_test_split - an integer - what portion of data to use for testing\n",
        "    \n",
        "    Return:\n",
        "    X_train, Y_train, X_test, Y_test, n_train, n_features\n",
        "    \"\"\"\n",
        "    \n",
        "    # Linear data or non-linear data?\n",
        "    if use_nonlinear:\n",
        "        weights = np.array([[1.0, 0.5, 0.2],[0.5, 0.3, 0.15]])\n",
        "    else:\n",
        "        weights = np.array([1.0, 0.5, 0.2])\n",
        "        \n",
        "\n",
        "    \n",
        "    bias = np.ones(n_points).reshape((-1,1))\n",
        "    low = - np.ones((n_points,n_features),'float')\n",
        "    high = np.ones((n_points,n_features),'float')\n",
        "        \n",
        "    np.random.seed(42)\n",
        "    X = np.random.uniform(low=low, high=high)\n",
        "    \n",
        "    np.random.seed(42)\n",
        "    noise = np.random.normal(size=(n_points, 1))\n",
        "    noise_std = 0.1\n",
        "    \n",
        "    if use_nonlinear:\n",
        "        Y = (weights[0,0] * bias + np.dot(X, weights[0, :]).reshape((-1,1)) + \n",
        "             np.dot(X*X, weights[1, :]).reshape([-1,1]) +\n",
        "             noise_std * noise)\n",
        "    else:\n",
        "        Y = (weights[0] * bias + np.dot(X, weights[:]).reshape((-1,1)) + \n",
        "             noise_std * noise)\n",
        "    \n",
        "    n_test = int(n_points/train_test_split)\n",
        "    n_train = n_points - n_test\n",
        "    \n",
        "    X_train = X[:n_train,:]\n",
        "    Y_train = Y[:n_train].reshape((-1,1))\n",
        "\n",
        "    X_test = X[n_train:,:]\n",
        "    Y_test = Y[n_train:].reshape((-1,1))\n",
        "    \n",
        "    return X_train, Y_train, X_test, Y_test, n_train, n_features\n",
        "\n",
        "X_train, Y_train, X_test, Y_test, n_train, n_features = generate_data(use_nonlinear=False)\n",
        "X_train.shape, Y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7500, 3), (7500, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9vK9sN_Y3Cu"
      },
      "source": [
        "### Linear Regression with Numpy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "eqxPhZwvY3Cu"
      },
      "source": [
        "# GRADED FUNCTION: numpy_lin_regress\n",
        "def numpy_lin_regress(X_train, Y_train):\n",
        "    \"\"\"\n",
        "    numpy_lin_regress - Implements linear regression model using numpy module\n",
        "    Arguments:\n",
        "    X_train  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    Return:\n",
        "    np.array of size (k+1 by 1) of regression coefficients\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (â‰ˆ 3 lines of code)\n",
        "    \n",
        "    # number of features\n",
        "    \n",
        "    K = len(X_train)\n",
        "    \n",
        "    # add the column of ones\n",
        "    X = np.hstack((np.ones(len(X_train)).reshape((-1, 1)), X_train))\n",
        "    \n",
        "    # default answer, replace this\n",
        "    theta_numpy = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_train)\n",
        "    ### END CODE HERE ###\n",
        "    return theta_numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSxSt71GY3Cv",
        "outputId": "1d729003-501c-4860-bdd4-cb248944a586"
      },
      "source": [
        "A = np.hstack((np.ones(2).reshape((-1, 1)), [[1],[2]]))\n",
        "\n",
        "print(A.T.dot(A))\n",
        "print(np.linalg.inv(A.T.dot(A)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.  3.]\n",
            " [ 3.  5.]]\n",
            "[[ 5. -3.]\n",
            " [-3.  2.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qo0bdseqY3Cv",
        "outputId": "93c7055c-4a77-486e-c993-c1e73c8c2d8c"
      },
      "source": [
        "### GRADED PART (DO NOT EDIT) ###\n",
        "theta_numpy = numpy_lin_regress(X_train, Y_train)\n",
        "part_1 = list(theta_numpy.squeeze())\n",
        "try:\n",
        "    part1 = \" \".join(map(repr, part_1))\n",
        "except TypeError:\n",
        "    part1 = repr(part_1)\n",
        "submissions[all_parts[0]]=part1\n",
        "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:1],all_parts,submissions)\n",
        "theta_numpy.squeeze()\n",
        "### GRADED PART (DO NOT EDIT) ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission successful, please check on the coursera grader page for the status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99946227,  0.99579039,  0.499198  ,  0.20019798])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBX_qLw5Y3Cv",
        "outputId": "1a500e12-59e6-432c-b6ca-5f40632f4937"
      },
      "source": [
        "X = np.hstack((np.ones(len(X_train)).reshape((-1, 1)), X_train))\n",
        "\n",
        "th_n = np.linalg.inv(X.T.dot(X)).dot(X.T).dot(Y_train)\n",
        "\n",
        "print(th_n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.99946227]\n",
            " [ 0.99579039]\n",
            " [ 0.499198  ]\n",
            " [ 0.20019798]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87-JgOgiY3Cw"
      },
      "source": [
        "### Linear Regression with Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "dzsgxbZqY3Cw"
      },
      "source": [
        "# GRADED FUNCTION: sklearn_lin_regress\n",
        "def sklearn_lin_regress(X_train, Y_train):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X_train  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    Return:\n",
        "    np.array of size (k+1 by 1) of regression coefficients\n",
        "    \"\"\" \n",
        "    from sklearn.linear_model import LinearRegression\n",
        "    lin_reg = LinearRegression()\n",
        "    ### START CODE HERE ### (â‰ˆ 3 lines of code)\n",
        "\n",
        "    \n",
        "    \n",
        "    lin_reg.fit(X_train, Y_train)\n",
        "    \n",
        "    \n",
        "    theta_sklearn = np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return theta_sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UeuZSV_Y3Cw",
        "outputId": "d965a82c-7796-4168-c352-333521f5a3f6"
      },
      "source": [
        "X_train, Y_train, X_test, Y_test, n_train, n_features = generate_data(use_nonlinear=False)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "lin_reg = LinearRegression()\n",
        "### START CODE HERE ### (â‰ˆ 3 lines of code)\n",
        "\n",
        "\n",
        "\n",
        "lin_reg.fit(X_train, Y_train)\n",
        "\n",
        "print(np.r_[lin_reg.intercept_.reshape(-1, 1), lin_reg.coef_.T])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.99946227]\n",
            " [ 0.99579039]\n",
            " [ 0.499198  ]\n",
            " [ 0.20019798]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFtFkm_0Y3Cx",
        "outputId": "5ff69833-29b7-4717-92f3-499c994794ad"
      },
      "source": [
        "### GRADED PART (DO NOT EDIT) ###\n",
        "theta_sklearn = sklearn_lin_regress(X_train, Y_train)\n",
        "part_2 = list(theta_sklearn.squeeze())\n",
        "try:\n",
        "    part2 = \" \".join(map(repr, part_2))\n",
        "except TypeError:\n",
        "    part2 = repr(part_2)\n",
        "submissions[all_parts[1]]=part2\n",
        "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:2],all_parts,submissions)\n",
        "theta_sklearn.squeeze()\n",
        "### GRADED PART (DO NOT EDIT) ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission successful, please check on the coursera grader page for the status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99946227,  0.99579039,  0.499198  ,  0.20019798])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HRINWNzFY3Cx"
      },
      "source": [
        "### Linear Regression with Tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "gb-GOYq5Y3Cx"
      },
      "source": [
        "# GRADED FUNCTION: tf_lin_regress\n",
        "def tf_lin_regress(X_train, Y_train):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "    X_train  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    Return:\n",
        "    np.array of size (k+1 by 1) of regression coefficients\n",
        "    \"\"\"\n",
        "    ### START CODE HERE ### (â‰ˆ 7-8 lines of code)\n",
        "    # add the column of ones\n",
        "    \n",
        "    X_np = np.hstack((np.ones(len(X_train)).reshape((-1, 1)), X_train))\n",
        "    \n",
        "    X = tf.constant(X_np, dtype=tf.float32, name=\"X\")\n",
        "    y = tf.constant(Y_train, dtype=tf.float32, name=\"Y\")\n",
        "    \n",
        "    XT = tf.transpose(X)\n",
        "    \n",
        "    theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)\n",
        "    \n",
        "    # define theta for later evaluation\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    with tf.Session() as sess:\n",
        "        theta_value = theta.eval()\n",
        "    return theta_value"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2ry8S59Y3Cx",
        "outputId": "7f559800-b429-4a16-fec0-c82594195b10"
      },
      "source": [
        "### GRADED PART (DO NOT EDIT) ###\n",
        "theta_tf = tf_lin_regress(X_train, Y_train)\n",
        "part_3 = list(theta_tf.squeeze())\n",
        "try:\n",
        "    part3 = \" \".join(map(repr, part_3))\n",
        "except TypeError:\n",
        "    part3 = repr(part_3)\n",
        "submissions[all_parts[2]]=part3\n",
        "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:3],all_parts,submissions)\n",
        "theta_tf.squeeze()\n",
        "### GRADED PART (DO NOT EDIT) ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission successful, please check on the coursera grader page for the status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99946201,  0.99579054,  0.49919799,  0.20019798], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "wd9xernAY3Cy"
      },
      "source": [
        "class LinRegressNormalEq:\n",
        "    \"\"\"\n",
        "    class LinRegressNormalEq - implements normal equation, maximum likelihood estimator (MLE) solution\n",
        "    \"\"\"\n",
        "    def __init__(self, n_features, learning_rate=0.05, L=0):\n",
        "        import math as m\n",
        "        # input placeholders\n",
        "        self.X = tf.placeholder(tf.float32, [None, n_features], name=\"X\") \n",
        "        self.Y = tf.placeholder(tf.float32, [None, 1], name=\"Y\")\n",
        "    \n",
        "        # regression parameters for the analytical solution using the Normal equation\n",
        "        self.theta_in = tf.placeholder(tf.float32, [n_features+1,None])\n",
        "\n",
        "        # Augmented data matrix is obtained by adding a column of ones to the data matrix\n",
        "        data_plus_bias = tf.concat([tf.ones([tf.shape(self.X)[0], 1]), self.X], axis=1)\n",
        "        \n",
        "        XT = tf.transpose(data_plus_bias)\n",
        "        \n",
        "        #############################################\n",
        "        # The normal equation for Linear Regression\n",
        "        \n",
        "        self.theta = tf.matmul(tf.matmul(\n",
        "            tf.matrix_inverse(tf.matmul(XT, data_plus_bias)), XT), self.Y)\n",
        "        \n",
        "        # mean square error in terms of theta = theta_in\n",
        "        self.lr_mse = tf.reduce_mean(tf.square(\n",
        "            tf.matmul(data_plus_bias, self.theta_in) - self.Y))\n",
        "                       \n",
        "        #############################################\n",
        "        # Estimate the model using the Maximum Likelihood Estimation (MLE)\n",
        "        \n",
        "        # regression parameters for the Maximum Likelihood method\n",
        "        # Note that there are n_features+2 parameters, as one is added for the intercept, \n",
        "        # and another one for the std of noise  \n",
        "        self.weights = tf.Variable(tf.random_normal([n_features+2, 1]))\n",
        "        \n",
        "        # prediction from the model\n",
        "        self.output = tf.matmul(data_plus_bias, self.weights[:-1, :])\n",
        "\n",
        "        gauss = tf.distributions.Normal(loc=0.0, scale=1.0)\n",
        "\n",
        "        # Standard deviation of the Gaussian noise is modelled as a square of the \n",
        "        # last model weight\n",
        "        sigma = 0.0001 + tf.square(self.weights[-1]) \n",
        "        \n",
        "        # though a constant sqrt(2*pi) is not needed to find the best parameters, here we keep it\n",
        "        # to get the value of the log-LL right \n",
        "        pi = tf.constant(m.pi)\n",
        "    \n",
        "        log_LL = tf.log(0.00001 + (1/( tf.sqrt(2*pi)*sigma)) * gauss.prob((self.Y - self.output) / sigma ))  \n",
        "        self.loss = - tf.reduce_mean(log_LL)\n",
        "        \n",
        "        self.train_step = (tf.train.AdamOptimizer(learning_rate).minimize(self.loss), -self.loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "-LAm1oj3Y3Cy"
      },
      "source": [
        "# GRADED FUNCTION: run_normal_eq\n",
        "def run_normal_eq(X_train, Y_train, X_test, Y_test, learning_rate=0.05):\n",
        "    \"\"\"\n",
        "    Implements normal equation using tensorflow, trains the model using training data set\n",
        "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
        "    \n",
        "    Arguments:\n",
        "    X_train  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    X_test  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    \n",
        "    Return a tuple of:\n",
        "        - np.array of size (k+1 by 1) of regression coefficients\n",
        "        - mean square error (MSE) of the test data set\n",
        "        - mean square error (MSE) of the training data set\n",
        "    \"\"\"\n",
        "    # create an instance of the Linear Regression model class  \n",
        "    n_features = X_train.shape[1]\n",
        "    model = LinRegressNormalEq(n_features=n_features, learning_rate=learning_rate)\n",
        "\n",
        "    ### START CODE HERE ### (â‰ˆ 10-15 lines of code)\n",
        "    # train the model\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Normal equation for Linear Regression\n",
        "        \n",
        "        theta_value = sess.run(model.theta, feed_dict={\n",
        "            model.X: X_train,\n",
        "            model.Y: Y_train\n",
        "        })\n",
        "        \n",
        "        lr_mse_train = sess.run(model.lr_mse, feed_dict={\n",
        "            model.X: X_train,\n",
        "            model.Y: Y_train,\n",
        "            model.theta_in: theta_value\n",
        "        })\n",
        "        \n",
        "        lr_mse_test = sess.run(model.lr_mse, feed_dict={\n",
        "            model.X: X_test,\n",
        "            model.Y: Y_test,\n",
        "            model.theta_in: theta_value\n",
        "        })\n",
        "        \n",
        "        \n",
        "        \n",
        "    ### END CODE HERE ###\n",
        "    return theta_value, lr_mse_train, lr_mse_test\n",
        "\n",
        "### (DO NOT EDIT) ###\n",
        "theta_value, lr_mse_train, lr_mse_test = run_normal_eq(X_train, Y_train, X_test, Y_test)\n",
        "### (DO NOT EDIT) ###"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVYTOcL3Y3Cz",
        "outputId": "629b557f-e2b5-4948-9935-6e2542baf8d0"
      },
      "source": [
        "### GRADED PART (DO NOT EDIT) ###\n",
        "part_4 = list(theta_value.squeeze())\n",
        "try:\n",
        "    part4 = \" \".join(map(repr, part_4))\n",
        "except TypeError:\n",
        "    part4 = repr(part_4)\n",
        "submissions[all_parts[3]]=part4\n",
        "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:4],all_parts,submissions)\n",
        "theta_value.squeeze()\n",
        "### GRADED PART (DO NOT EDIT) ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission successful, please check on the coursera grader page for the status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99946201,  0.99579054,  0.49919799,  0.20019798], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "0EY2lKWoY3Cz"
      },
      "source": [
        "# GRADED FUNCTION: run_mle# GRADED \n",
        "def run_mle(X_train, Y_train, X_test, Y_test, learning_rate=0.05, num_iter=5000):\n",
        "    \"\"\"\n",
        "    Maximum likelihood Estimate (MLE)\n",
        "    Tests the model quality by computing mean square error (MSE) of the test data set\n",
        "    \n",
        "    Arguments:\n",
        "    X_train  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_train - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    X_test  - np.array of size (n by k) where n is number of observations \n",
        "                of independent variables and k is number of variables\n",
        "    Y_test - np.array of size (n by 1) where n is the number of observations of dependend variable\n",
        "    \n",
        "    \n",
        "    Return a tuple of:\n",
        "        - np.array of size (k+1 by 1) of regression coefficients\n",
        "        - mean square error (MSE) of the test data set\n",
        "        - mean square error (MSE) of the training data set\n",
        "    \"\"\"\n",
        "    # create an instance of the Linear Regression model class  \n",
        "    n_features = X_train.shape[1]\n",
        "    model = LinRegressNormalEq(n_features=n_features, learning_rate=learning_rate)\n",
        "    \n",
        "    # train the model\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(tf.global_variables_initializer())\n",
        "\n",
        "        # Now train the MLE parameters \n",
        "        for _ in range(num_iter):\n",
        "            (_ , loss), weights = sess.run((model.train_step, model.weights), feed_dict={\n",
        "                model.X: X_train,\n",
        "                model.Y: Y_train\n",
        "                })\n",
        "\n",
        "        # make test_prediction\n",
        "        Y_test_predicted = sess.run(model.output, feed_dict={model.X: X_test})\n",
        "\n",
        "        # output std sigma is a square of the last weight\n",
        "        std_model = weights[-1]**2 \n",
        "        sess.close()\n",
        "    return weights[0:-1].squeeze(), loss, std_model\n",
        "\n",
        "weights, loss, std_model = run_mle(X_train, Y_train, X_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WJYqlbcY3Cz",
        "outputId": "4d85f266-ea4e-4a1d-f7d0-2f439793540d"
      },
      "source": [
        "### GRADED PART (DO NOT EDIT) ###\n",
        "part_5 = list(weights.squeeze())\n",
        "try:\n",
        "    part5 = \" \".join(map(repr, part_5))\n",
        "except TypeError:\n",
        "    part5 = repr(part_5)\n",
        "submissions[all_parts[4]]=part5\n",
        "grading.submit(COURSERA_EMAIL, COURSERA_TOKEN, assignment_key,all_parts[:5],all_parts,submissions)\n",
        "weights.squeeze()\n",
        "### GRADED PART (DO NOT EDIT) ###"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submission successful, please check on the coursera grader page for the status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.99956113,  0.9959684 ,  0.49927232,  0.20010588], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "laz1dXE8Y3C0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
